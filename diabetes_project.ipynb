{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1:  setting up\n",
    "Luckily for us as programmers and data scientists we don't have to write all our code from scratch.\n",
    "There are a lot of code libraries and modules available for many of the common tasks we will need to carry out.\n",
    "The first step, before we start looking at data is to load some of these modules so that we can call on them in our code.The modules we are going to import are:\n",
    "\n",
    "- pandas: a popular general-purpose data analysis library which allows importing data from various file formats. It also provides useful data structures which can be used to examine and edit data\n",
    "\n",
    "- numpy: a popular library for performing mathematical operations, particularly with matrices and arrays.\n",
    "\n",
    "- matplotlib: a library for plotting charts and other visualisations.\n",
    "\n",
    "- Seaborn: a library which uses matplotlib and provides extra functions for visualising statistical analysis results.\n",
    "\n",
    "- toolbox_module: this contains some python functions we wrote to perform complex tasks which need very long blocks of code.\n",
    "importing them means we don't have to write them in this notebook, making it easier for you to read. As you progress with\n",
    "python you will do this a lot with your own code.\n",
    "\n",
    "You will need to run the code in the next cell so that al the code that relies on these libraries can work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Loading libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import toolbox_module as tools\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Loading the Data\n",
    "Now we are going to import the data set. It is in a .csv file in a folder called 'data' the same directory as this notebook.\n",
    "We are making a variable called 'df'. We also have access to a variable 'pd' which we created in the previous cell when\n",
    "we imported _pandas._ We are calling a function in pandas (pd) called 'read()' which uses the location of the data as a string argument to load a\n",
    "dataset into a pandas _dataframe_ (think of this as a table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv(\"data/diabetic_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the data\n",
    "Now we have our data in a dataframe we can start examining and manipulating it.\n",
    "Now let's explore the data. The first command we will use is in the cell below: `df.shape` this will return two values\n",
    "in parentheses (in Python we call this a _tuple_). The first value is the number of rows in our dataset; the second is the\n",
    "number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### In your Notebook...\n",
    "1. How many rows of data are in this dataset?\n",
    "2. Could you open this data easily in Excel?\n",
    "\n",
    "The next command we will try is `.head()` By default this will display the first 5 lines of data. It is useful for\n",
    "giving a general idea of what the data looks like. If you put a number in the brackets it will return that amount of data\n",
    "\n",
    "### try...\n",
    "Type a number into the brackets and re-run the cell (if you tried to be a clever-clogs and typed 1000 like I would have\n",
    "done ;-) you can get rid of it by re-running the cell with a smaller number. \n",
    "If you type ````.T```` on the end it will flip the table view so the columns display as rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# type your code below\n",
    "df.head(100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#we could put the stacktrace bit in the getting started section....\n",
    "\n",
    "If everything went OK you should see the first 5 rows of data. If not you will see a lot of red text called a _stack trace_.\n",
    "Don't worry about this. It might look alarming but it often includes helpful information about where you went wrong.\n",
    "If you do see a stack trace, make sure your code in the cell above looks like this `df.head()` once it does, and you\n",
    "re-run the cell the stacktrace will be gone.\n",
    "### try\n",
    "replace `df.head()` with `df.hea()`\n",
    "### in your Notebook\n",
    "What did the output look like?  Look at it carefully. How might that help you work out\n",
    "what went wrong?\n",
    "\n",
    "now put df.head() back into the cell and re-run it.\n",
    "\n",
    "The dataset should have 101766 rows, and 50 columns. That's a lot of data to make sense of, but we have the tools!\n",
    "Let's see what types of data we have. The command to do this is `df.dtypes` try it in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next to each column you can see data type. for example _int64_ is an integer. When Pandas isn't sure what\n",
    "the type should be it uses 'object'. These are mostly strings as this is data coming from a .CSV file.\n",
    "Now we know what our data looks like lets make sure it is in a suitable state for us to analyse. One of the first things\n",
    "to do is deal with any missing values.\n",
    "\n",
    "In this dataset, missing values are represented by a  “?”  So if we search every column which has a type of “object” to\n",
    "see if there are any “?” values, and then count them, we can see the extent of any missing data problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# note to self - do we need to take them through series and referencing pandas dataframes ? Or can we just explain what it does\n",
    "\n",
    "# for every column in the dataframe\n",
    "for col in df.columns:\n",
    "    # check if it has a datatype of 'object' - if it does\n",
    "    if df[col].dtype == object:\n",
    "        #print the column name and the count of the number of '?' values\n",
    "         print(col,df[col][df[col] == '?'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that 'Gender' is encoded differently with 'Unknown/Invalid' used to signify missing data.\n",
    "so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tools.count_value(df, 'Unknown/Invalid', 'gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Cleaning up the Data: Missing values.\n",
    "\n",
    "We can see that some columns have quite a few missing values. Weight is the worst affected with around 98% of\n",
    "the values missing. There is not much we can do to improve this situation so we will remove this column from the dataset.\n",
    "Payer code and medical specialty also have a lot of missing values so we will also drop these columns. 2 other variables\n",
    "the drugs named <drug names> all have the same values and therefore do not add any information, so we will also drop these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dropping columns with large number of missing values\n",
    "df = df.drop(['weight','payer_code','medical_specialty'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The columns race, diagnoses and gender all have some missing values but far fewer than the columns we have just dropped.\n",
    "In this situation, we can just go in and delete those values. We will do this with a function from our toolbox module.\n",
    "Once we have done this we can rerun the code we used earlier to see what our dataset looks like now we have cleaned it\n",
    "up a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tools.drop_values(df,'race','?')\n",
    "tools.drop_values(df,'diag_1', '?')\n",
    "tools.drop_values(df,'diag_2', '?')\n",
    "tools.drop_values(df,'diag_3', '?')\n",
    "tools.drop_values(df,'gender', 'Unknown/Invalid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feature Engineering\n",
    "So we have cleaned up the data and now have a dataset free from missing values, but there are still some issues.\n",
    "The dataset wasn't designed specifically with machine learning in mind, and some of the variables need to be optimised.\n",
    "There are also some potential new features an algorithm could use.\n",
    "\n",
    "### Previous Diagnoses\n",
    "There are three columns in the dataframe: ``diag1``, ``diag2`` and ``diag3`` which are references to previous diagnoses.\n",
    "These use something called an IDC code to indicate what the diagnosis was.\n",
    "There are several hundred distinct values which are strings, mostly numeric.\n",
    "we can simplify this into something our model can make sense out of by categorising them. In another study, researchers\n",
    "used nine desease categories and we have done the same, assigning each a single digit identifier:\n",
    "circulatory = 1, respiratory = 2,digestive = 3,diabetes = 4,injury = 5,musculoskeletal = 6,\n",
    "genitourinary = 7, neoplasm = 8 and other = 9\n",
    "\n",
    "We have provided a function in the toolbox_module which does this for you: `convert_idc_disease_class()`\n",
    "This accepts a string and returns an integer between 1 and 9.\n",
    "#### try...\n",
    "patient x has a diag_1 code of '648'. what type of condition did they suffer from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#write your code below...\n",
    "tools.convert_idc_disease_class('648') #todo: delete me - I'm a solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The three lines of code in the cell below apply this function to every row in the dataframe and put the result in a new\n",
    "column. This uses a feature you will come across in many programming languages, called a _lambda function_. It works by\n",
    "passing a bit of code as an argument to a function. The code then runs inside the function and enhances it.\n",
    "\n",
    "You can see the Keyword `Lambda` and `row`followed by a colon. `row` is a parameter for the dataframe's `apply` function.\n",
    "After the colon we pass our toolbox function which is applied to every row in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diag_1_cat']=df.apply(lambda row:tools.convert_idc_disease_class(row['diag_1']), axis=1)\n",
    "df['diag_2_cat']=df.apply(lambda row:tools.convert_idc_disease_class(row['diag_2']), axis=1)\n",
    "df['diag_3_cat']=df.apply(lambda row:tools.convert_idc_disease_class(row['diag_3']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now lets run df head again. Can you see what's changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.head(100).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drug prescribing\n",
    "There are 23 drugs which have been prescribed as part of diabetes treatment protocols and the dataset records whether\n",
    "the prescription was increased, reduced, not prescribed, or continued without change.\n",
    "Have a look at the `head()` output to see them.\n",
    "We are aware of previous research which has found that changes to medication is associated with lower readmission rates,\n",
    "so we are going to make a new variable - a *__'feature'__* for our machine learning algorithm called ``numchange`` which\n",
    "is the total number of changes to any medication.\n",
    "\n",
    "To do that we make a list of all the medications (keys), and then we loop over this making a temporary column in the\n",
    "dataframe for each key and then using a *__lambda__* function like we did earlier. This creates a variable “X” which stores\n",
    "the value of the column, which we test: if it is equal to 'no' or 'steady', then the medication either has not been\n",
    "prescribed or dosage not changed in which case we assign 0. If it has any other value, i.e. “up”, or “down” then the\n",
    "dosages either been increased or decreased, in which case we assign one. \n",
    "\n",
    "Once we have done that we loop over the keys again, this time adding the value of the temporary column to the `numchange` column. Finally we delete the temporary column. The last line of code outputs the number of different values in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# set up the list of drugs - the columns we are using\n",
    "keys = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'glipizide', 'glyburide',\n",
    "        'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'insulin', 'glyburide-metformin', 'tolazamide',\n",
    "        'metformin-pioglitazone','metformin-rosiglitazone', 'glimepiride-pioglitazone', 'glipizide-metformin',\n",
    "        'troglitazone', 'tolbutamide', 'acetohexamide']\n",
    "\n",
    "##loop over the drug columns, and for every drug...\n",
    "for col in keys:\n",
    "    #... make a temporary column\n",
    "    colname = str(col) + 'temp'\n",
    "    #...then check for changes to medications: assign 1 to the temporary column if there were changes, otherwise 0\n",
    "    df[colname] = df[col].apply(lambda x: 0 if (x == 'No' or x == 'Steady') else 1)\n",
    "\n",
    "#make a numchange column: we do this outside the loop, why?\n",
    "df['numchange'] = 0\n",
    "\n",
    "# now we loop over them again\n",
    "for col in keys:\n",
    "    #remake the name of the temporary column\n",
    "    colname = str(col) + 'temp'\n",
    "\n",
    "    # add the value to the numchange column\n",
    "    df['numchange'] = df['numchange'] + df[colname]\n",
    "    # delete the temorary column\n",
    "    del df[colname]\n",
    "\n",
    "#print out a list of all the 'numchange' values we have and how many\n",
    "df['numchange'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In your notebook...\n",
    "What percentage of people did not have changes to their medications?\n",
    "## Encoding\n",
    "The dataset uses strings for gender, race, diabetesMed, and medication change, and for each of the 23 drugs used. To use these values in our\n",
    "model we are going to convert them into binary values, i.e. 1 and 0.\n",
    "#### Medication Change\n",
    "First, we will deal with medication change by replacing ‘Ch’ with 1 and ‘No’ with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['change'] = df['change'].replace('Ch', 1)\n",
    "df['change'] = df['change'].replace('No', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### diabetesMed\n",
    "...then we will change diabetesMed by replacing yes with 1 and no with 0. This is a convention in programming when\n",
    "converting things into binary. 'yes' is generally represented by '1' and 'no' generally by '0', a bit like a Boolean value,\n",
    "where 'True' is represented by '1' and 'False' by '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['diabetesMed'] = df['diabetesMed'].replace('Yes', 1)\n",
    "df['diabetesMed'] = df['diabetesMed'].replace('No', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### try...\n",
    "#### Gender\n",
    "Now it is your turn. Let’s encode gender by encoding 'Male' with 1 and 'Female' with 0. You can do this in tha same way\n",
    "as we did in the cells above Have a look at the dataset to make sure that you type 'Male' and 'Female' exactly as they are\n",
    "in the dataset. Clue: both capitalised"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# write your code below...\n",
    "df['gender'] = df['gender'].replace('Male', 1)\n",
    "df['gender'] = df['gender'].replace('Female', 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ethnicity\n",
    "The column ‘ethnicity’ currently has text values to describe the ethnic background of patients. Typical values include\n",
    "“African/American”, “Caucasian”, “Hispanic”, and “other”. Machine learning algorithms prefer numerical or binary values\n",
    "so to improve our data, we will create a column for each of the text values and indicate the ethnicity by placing a “1”\n",
    "in the correct column and “0” in all the others. These are known as “dummy variables”, and we are using the pandas dataframe\n",
    "function ``get_dummies()`` in the cell below to create them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['race'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Medications\n",
    "The dataset contains 23 columns each for a different medication. Each medication feature indicates whether the drug was\n",
    "prescribed and whether there was a change in dosage.As we have already created a variable that measures the amount of\n",
    "changes in medication alongside the existence of another variable which indicates whether or not there was a change, we\n",
    "don't really need this information, so we are going to recode these variables so that they just indicate whether or not\n",
    "this particular drug was prescribed. We are going to loop through the set of drug keys we created earlier. This time,\n",
    "for each drug, we will replace the values: 0 for ‘no’;1 for steady, up, down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# we are using the list of keys from the cell we created them in earlier\n",
    "for col in keys:\n",
    "    df[col] = df[col].replace('No', 0)\n",
    "    df[col] = df[col].replace('Steady', 1)\n",
    "    df[col] = df[col].replace('Up', 1)\n",
    "    df[col] = df[col].replace('Down', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of medications\n",
    "Number of each medication used: Another potentially interesting factor could be the total number of medications used by the\n",
    "patient. This might indicate the severity of their condition and/or the intensity of their care, so we created another\n",
    "feature - num_meds by counting the medications used during the stay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# make a new column\n",
    "df['num_meds'] = 0\n",
    "# loop through the list of drugs we made earlier\n",
    "for col in keys:\n",
    "    # there will now be a '1' in the column if the patient is on that drug, so add it to the number of meds\n",
    "    # (add the '0' otherwise)\n",
    "    df['num_meds'] = df['num_meds'] + df[col]\n",
    "# print a count of the values to make sure it worked\n",
    "df['num_meds'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Results\n",
    "We are also going to recode test results for the A1c test (we are data scientists and we have no idea what that is), and\n",
    "the maximum glucose serum test. We are going to encode 0 for a normal result and 1 for an abnormal result.\n",
    "Where no test was given, we will use -99.\n",
    "#### in your notebook...\n",
    "Have a look at the code in the cell below, what are the abnormal values for each test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['A1Cresult'] = df['A1Cresult'].replace('>7', 1)\n",
    "df['A1Cresult'] = df['A1Cresult'].replace('>8', 1)\n",
    "df['A1Cresult'] = df['A1Cresult'].replace('Norm', 0)\n",
    "df['A1Cresult'] = df['A1Cresult'].replace('None', -99)\n",
    "df['max_glu_serum'] = df['max_glu_serum'].replace('>200', 1)\n",
    "df['max_glu_serum'] = df['max_glu_serum'].replace('>300', 1)\n",
    "df['max_glu_serum'] = df['max_glu_serum'].replace('Norm', 0)\n",
    "df['max_glu_serum'] = df['max_glu_serum'].replace('None', -99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Groupings\n",
    "The age variable is currently encoded in 10 year intervals: 10 year bands from 0 to 100. We are going to create a loop\n",
    "which runs 10 times and replaces each band with an integer. What we are left with is still a categorical variable, so we\n",
    "will approximate the age as the midpoint in each category, so we are left with something on a continuous scale.\n",
    "\n",
    "To do this we use a feature in python called a dictionary. This is a data structure which is a type of *__collection__*. It's a  a bit like a list, but it consists of key value pairs separated by a colon. The key comes first, and we can use this to look up values in the dictionary in much the same way you would get the definition of a word from a real-life dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# code age intervals [0-10) - [90-100) from 1-10\n",
    "for i in range(0,10): #for every number from 1-10\n",
    "    #make a string using i which matches the interval eg '[10-20)', replace this with i+1\n",
    "    df['age'] = df['age'].replace('['+str(10*i)+'-'+str(10*(i+1))+')', i+1)\n",
    "df['age'].value_counts()\n",
    "\n",
    "#convert 'age' into an integer\n",
    "df['age'] = df['age'].astype('int64')\n",
    "#print out a count of all the values. This keep us sane!\n",
    "print(df.age.value_counts())\n",
    "\n",
    "# make a dictionary so we can look up new values to replace the ones we made earlier\n",
    "age_dict = {1:5, 2:15, 3:25, 4:35, 5:45, 6:55, 7:65, 8:75, 9:85, 10:95}\n",
    "\n",
    "#map the values onto those in the dictionary. This will replace each one\n",
    "df['age'] = df.age.map(age_dict)\n",
    "#print out the new value counts so we know it worked\n",
    "print(df.age.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the outcome variable\n",
    "The outcome variable is the thing we are trying to predict. As it currently stands it has the values 'no', '>30' and\n",
    "'<30' representing not readmitted, readmitted in less than 30 days and readmitted after more than 30 days.\n",
    "You can see the current values by running ``value_counts()`` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['readmitted'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are going to encode the outcome variable so that readmission within 30 days is indicated as a 1 and no readmission or\n",
    "readmission later than 30 days is indicated as a 0. We will do this with the pandas replace function in the cell below."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['readmitted'] = df['readmitted'].replace('>30', 0)\n",
    "df['readmitted'] = df['readmitted'].replace('<30', 1)\n",
    "df['readmitted'] = df['readmitted'].replace('NO', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualisations\n",
    "Another important step in a machine learning project is visual inspection of the data. We had a look at the output\n",
    "from the `head()` command, but as humans we can only make sense of this one column at a time, so we can only use it to\n",
    "inspect a tiny fraction of the data. We need other strategies to get a picture of what the whole dataset looks like,\n",
    "so let’s build some charts…\n",
    "\n",
    "Remember those imports we did at the start of this notebook? One of them was *__Seaborn__* which is a statistical\n",
    "visualisation library. We imported it as `sns`. This means we can use it to produce charts by calling its functions.\n",
    "The seaborne library is based on *__matplotlib__* and uses many of its functions, so when we write code, we might call\n",
    "functions from matplotlib (`plt`) as well as seaborne in the same chart.\n",
    "\n",
    "Let's start with a nice simple one and plot _age_ and _readmission_ as a bar chart..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age and Readmission\n",
    "First, we create a `fig` variable by calling the `figure` method from `plt` which is a quick way of setting the size of the graphic.\n",
    "Any matplotlib or seaborne code we call now will operate on this fig variable until we make a new one.\n",
    "Next we call `sns.countplot()` to create a simple bar chart counting the values of a categorical variable using a column\n",
    "from the data frame as the first argument (`y=`) to measure on the x-axis, and then use the column supplied as the `hue` argument,\n",
    "which groups and colours the bars along the y-axis according to a second categorical variable.\n",
    "### try...\n",
    "See if you can flip the chart around by changing the name of the first argument. Which looks better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "chart = sns.countplot(y= df['age'], hue = df['readmitted'])\n",
    "chart.set_title('Age of Patient VS. Readmission')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now for a slightly more complex example. This next chart plots time in hospital and frequency of those readmitted, and\n",
    "those not readmitted on separate lines. The first line sets up a figure in much the same way as we did in the previous\n",
    "cell. This time we use the Kd E plot function. KDE stands for “kernel density estimate” and is a method for visualising\n",
    "the distribution of observations on a dataset. It is a bit like a histogram but represents the data using a curve. We\n",
    "use it twice to add two lines to the figure. The first arguments we pass for each line get a list of all the values of\n",
    "“readmitted” which satisfy the condition, i.e. `== 0`, or `== 1` as well as values for time in hospital.\n",
    "The other arguments shade the area under the curve and colour it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13,7),)\n",
    "ax=sns.kdeplot(df.loc[(df['readmitted'] == 0),'time_in_hospital'] , color='b',shade=True,bw_adjust=2, label='Not Readmitted')\n",
    "ax=sns.kdeplot(df.loc[(df['readmitted'] == 1),'time_in_hospital'] , color='r',shade=True,bw_adjust=2 , label='Readmitted')\n",
    "ax.set(xlabel='Time in Hospital', ylabel='Frequency')\n",
    "plt.title('Time in Hospital VS. Readmission')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Try…\n",
    "Now it's your turn. Use the cell below to plot some more of data. As you explore, make a note of anything you see which\n",
    "is unusual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# type your code below...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Modeling\n",
    "There are lots more things we could do to this data to improve our predictions still further, but the boss has said we\n",
    "have to finish this by lunchtime, so let's quickly deploy our algorithm and make some life or death decisions because\n",
    "work/life balance is important and nobody likes working on their lunch hour, right?\n",
    "\n",
    "Anyway, onwards! The next thing to do is identify the features we will use and separate out the target variable we are\n",
    "trying to predict.\n",
    "\n",
    "In the cell below we made a list of the features we are going to use to train the model. The last two lines in the cell\n",
    "extract the features from the database into a variable called X. The other line extracts the target feature, i.e. the\n",
    "one whose value we are learning to predict into a variable y. The use of uppercase X and lowercase y for features and\n",
    "target variable is a convention you will see quite often.\n",
    "\n",
    "We are going to use a library called *__Scikit-Learn__* to do our machine learning. Scikit-Learn is a collection of modules\n",
    "which give us a number of algorithms to try out, and we are going to experiment with two of them. The techniques we are\n",
    "going to use are *__supervised algorithms__*. We say this because these techniques use data which is labelled with the values\n",
    "we are trying to predict, so that we know what the output should be. We use this to create a model based on the\n",
    "relationship between our training variables and these known outputs. _Unsupervised learning_ techniques work without this\n",
    "knowledge and find relationships within the data independently.\n",
    "\n",
    "Our task is a classification task in that we are classifying patients based on whether they will or will not be\n",
    "readmitted to hospital within 30 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#noodling about - TODO: delete me when ready to publish\n",
    "feature_set1 = [ 'gender', 'age', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "               'time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient',\n",
    "               'number_emergency', 'number_inpatient',  'number_diagnoses', 'max_glu_serum',\n",
    "               'A1Cresult', 'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide',\n",
    "               'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol',\n",
    "               'troglitazone', 'tolazamide',  'insulin', 'glyburide-metformin',\n",
    "               'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone',\n",
    "               'change', 'diabetesMed', 'diag_1_cat', 'diag_2_cat', 'diag_3_cat', 'numchange', 'race_AfricanAmerican',\n",
    "               'race_Asian','race_Caucasian','race_Hispanic','race_Other']\n",
    "\n",
    "# specify which columns we are going to use as features for our model\n",
    "feature_set = [ 'gender', 'age', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
    "               'time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient',\n",
    "               'number_emergency', 'number_inpatient',  'number_diagnoses', 'max_glu_serum',\n",
    "               'A1Cresult', 'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide',\n",
    "               'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol',\n",
    "               'troglitazone', 'tolazamide',  'insulin', 'glyburide-metformin',\n",
    "               'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone',\n",
    "               'change', 'diabetesMed', 'diag_1_cat', 'diag_2_cat', 'diag_3_cat', 'numchange', 'race_AfricanAmerican',\n",
    "               'race_Asian','race_Caucasian','race_Hispanic','race_Other']\n",
    "\n",
    "\n",
    "X = df[feature_set]\n",
    "y = df['readmitted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and Training Data\n",
    "We need some way of testing the performance of our model. The way we do this is by taking out and reserving a section of\n",
    "our data as a test set, and then training the model with the rest. We then use it to make predictions based on the test\n",
    "data and compare those to the actual values to see how well we did. Usually we keep aside 20% of our data for testing\n",
    "purposes. Scikit-Learn has a module to do this, and we are going to import that and run a function to split the data.\n",
    "We will end up with 4 sets. 2 sets of features ``X_train`` and ``X_test`` and 2 sets of targets ``y_train`` and``y_test``- the values we are\n",
    "trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## The decision tree\n",
    "The first algorithm we are going to try is the decision tree. It is called a decision tree because the way it works\n",
    "internally is a bit like a flowchart with a treelike structure. At each node of the tree the algorithm finds the most\n",
    "efficient way of classifying the data. It keeps splitting the dataset at every node until eventually all the data points\n",
    "at each end of the tree are in the same class.\n",
    "\n",
    "In the next cell we have imported a decision tree classifier and created an instance of one as a variable called dtree.\n",
    "The classifier has a function called `fit()` and we pass it all the values from our dataset that we are going to use for\n",
    "training along with the values for the target variable. The decision tree classifier then makes a model based on the\n",
    "relationships it finds between our training data and the target values. Once that is done we can create a set of predicted\n",
    "values by calling ```dtree.predict(X_test)``` We use the test data for this so that we can check it against the actual\n",
    "values we kept in `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "dtree = DecisionTreeClassifier(max_depth=28, criterion = \"entropy\", min_samples_split=10)\n",
    "dtree.fit(X_train, y_train)\n",
    "dtree_predictions=dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can check how well our model is doing, using some more functions from Scikit-Learn called ``accuracy score()``,\n",
    "``precision score``, and ``recall score()``. We pass these our known target values, along with the predictions and\n",
    "print them out in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"DT-Accuracy is {0:.2f}\".format(accuracy_score(y_test, dtree_predictions)))\n",
    "print(\"DT-Precision is {0:.2f}\".format(precision_score(y_test, dtree_predictions)))\n",
    "print(\"DT-Recall is {0:.2f}\".format(recall_score(y_test, dtree_predictions)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally we have some results and our accuracy is 89%! Great! Time for pizza! Most pizza places in Southampton don’t\n",
    "need to be told where our building is on campus...\n",
    "\n",
    "_Not so fast!_ Accuracy is a simple measure of the number of correct predictions. We have to be a bit careful about relying\n",
    "on this beacuse if we created our own model which did not bother analysing any of the data and just said no patients were\n",
    "ever readmitted, then in a dataset where 80% of the patients were not readmitted we will be right 80% of the time!\n",
    "That is why we need some other metrics and you may notice we have also printed out two others called _precision_ and _recall_.\n",
    "\n",
    "* __Precision__ is slightly different from accuracy in that it only measures the rate of false positives, i.e. what proportion\n",
    "of patients who we predicted would be readmitted actually were.\n",
    "\n",
    "* __Recall__, on the other hand, measures the proportion of people who were actually readmitted, who we correctly identified as such.\n",
    "\n",
    "So our results are not looking very good despite the rather more impressive looking accuracy figure.\n",
    "\n",
    "...Except that these metrics don't work quite so well with decision trees, so we will also look at something called\n",
    "the *__AUC score__*.\n",
    "Trying to define and understand how awk scores work just before lunch can result in stomach ulcers according to another\n",
    "study I just made up, so we will just accept that simply put, an AUC score measures how well the model performs when\n",
    "compared to something that just makes random predictions. An orc score of 0 means a model is not random but is making\n",
    "incorrect predictions 100% of the time. An orc score 0.5 means the model is right about half the time, i.e. it is making\n",
    "random predictions. An orc score of 1.0 means model is correct 100% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import  roc_auc_score\n",
    "print('ROC AUC SCORE')\n",
    "print(roc_auc_score(y_test, dtree.predict_proba(X_test)[:,1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Oh dear, still not great. We're only doing slightly better than we would with a dice!\n",
    "\n",
    "### Enough Trees, Time For a Forest\n",
    "Another algorithm we could try, which might improve things, is called a *__Random Forest__*. If you are wondering what the\n",
    "difference between this and a decision tree is, the clue is in the name. A random Forest runs lots of decision trees\n",
    "and then averages the results. In the code below we have fit a random forest model in much the same way we did for the\n",
    "decision tree. The result is a slight improvement but still no pizza"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 50, max_depth=25, criterion = \"gini\", min_samples_split=10)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_predict=rf.predict(X_test)\n",
    "\n",
    "print(\"rf-Accuracy is {0:.2f}\".format(accuracy_score(y_test, rf_predict)))\n",
    "print(\"rf-Precision is {0:.2f}\".format(precision_score(y_test, rf_predict)))\n",
    "print(\"rf-Recall is {0:.2f}\".format(recall_score(y_test, rf_predict)))\n",
    "print(\"AUC score is {0:.2f}\".format(roc_auc_score(y_test, rf.predict_proba(X_test)[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that is looking a little bit better!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}